미세먼지를 통한 비즈니스 아이디어

가설: 
미세먼지에 따라 실내활동이 증가할 것이고 이에 따라 카드 사용량이 달라질 것이다

[미세먼지 고려사항]
1.k-weather를 통해 미세먼지 농도
2.인터넷의 시대로써 와이즈넛에서 제공하는 미세먼지 뉴스 건수
3.특히 봄과 여름을 시간의 기준으로 설정

[방법]
1.Spearman 상관계수를 통해 신한 업종별 이용건수와 gs 카테고리별 매출 중에서 미세먼지 뉴스건수와 상관관계가 높은 항목 정리
2.DT를 이용하여 신한 업종별 이용건수와 gs 카테고리별 매출 중에서 미세먼지 뉴스 외에 영향을 많이 받는 항목 제거(ex. 온도, 강수, 습도)
3.1,2번을 종합해 찾은 요소들이 회귀 분석을 통해 통계적으로 유의한지 검증(OLS regression)
3-1. R-square: > 0.3
3-2. p-value:  < 0.5

[결론]
최종적으로 선택된 업종들을 기반으로 미세먼지먼지와 라이플의 밸런스를 조절하는 “미라밸” 카드 – 미세먼지가 심할 때, 실내활동을 권장
Ex) 극장, 공연장, 목욕탕, 화장품, 볼링장, 노래방, 당구장, PC방, 비디오방, 식당

[Detail]
1. Correlation
정의: 변수간 연관성을 확인하는 방법(원인과 결과의 관계가 아님)
상관계수는 두 숫자형 변수사이의 연관성 중 선형성
- 공분산(Covariance): 두 숫자형 변수가 같은 방향으로 움직이는 정도
  : Cov(x,y) = E[(x-mx)(y-my)]
- 상관계수(Correlation coefficient): 공분산을 각각의 표준편차로 나누어준 값
  : Corr(x,y) = Cov(x,y)/(std(x)*std(y)
- Pearson: 선형성적인 분석, 모수검정
- Spearman: 각 변수의 값들을 rank화하여 분석하는 방식으로 단조관계 표현(비선형)
- Kendall Tau: 스피어맨과 같이 비선형성(단조관계), 샘플사이즈가 작거나 데이터의 동률이 많을 때 유용
- Why spearman?
피어슨을 사용하였을 때, 그 값들이 매우 낮았다. 이를 통해 비선형적인 관계가 있지 않을까 의심
데이터 샘플 수가 그렇게 많지는 않았지만 데이터의 동률이 많지 않아 켄달의 타우보다는 스피어맨을 사용해보기로 했고 결과도 잘 나와 사용. 
이를 통해 미세먼지 뉴스 건수와 상관관계가 큰 업종들을 추릴 수 있었다.

2. Decision Tree
설명:
의사 결정 나무라고 불리며 분류와 회귀 모두 가능한 지도학습 모델
각 노드에서 특정 feature에 따라 이진 분류를 지속적으로 진행함, 깊이가 깊어질수록 overfitting이 생길 수 있다
- 가지치기(pruning)
트리에서 가지가 너무 많으면 오버피팅이 생겼다고 할 수 있다.
최대 깊이, 터미널 노드의 최대 개수, 한 노드가 분할하기 위한 최소 데이터 수 등
- 알고리즘: Entropy, Impurity
불순도(impurity)란 해당 범주 안에 서로 다른 데이터가 섞여 있는 정도
엔트로피(Emtropy)는 불순도를 수치적으로 나타낸 척도로 엔트로피가 높다는 것은 불순도가 높다는 뜻으로 해당 범주에는 다른 클래스의 데이터들이 많이 섞여 있다. 
Entropy = -Summation(pi*log(pi)) where pi는 한 영역 안에 존재하는 데이터 가운데 i 범주에 속하는 데이터의 비율
- 정보 획득(information gain)
엔트로피의 변화량 = Entropy(parent) – [weighted avg]Entropy(children)

따라서 DT는 information gain(정보 획득)을 최대화 하는 방향으로 학습(엔트로피를 최소화하는 방향)

- feature importance
Information gain을 통해 각 분기에서의 feature의 중요도를 평가할 수 있다
우리는 이를 통해 미세먼지 뉴스건수 이외의 요인이 중요하게 작동한 요소는 제거하여 미세먼지 뉴스 건수에 영향을 크게 받은 업체만 남겼다

3. OLS regression
정의
오차를 최소화하여 회귀계수를 결정하는 방법입니다.
두 변수간의 회귀 계수를 결정하는 방법으로 선형방정식을 통해 구한 예측 값과 실제 값의 차이를 최소화하는 방법으로 선형 계수를 추정하는 방법입니다.
- Least Square Method
Error = Sum[(y_pred – y_true)^2]
- 귀무가설 vs 대립가설
귀무가설: 통계학에서 처음부터 버릴 것을 예상하는 가설
대립가설: 우리가 주장하고자 하는 가설
따라서 귀무가설을 기각함으로써 대립가설인 우리의 주장을 내세운다
- R-square
회귀 모델에서 독립변수가 종속변수를 얼마만큼 설명해 주는지를 가리키는 지표(설명력)
1에 가까울수록 설명력이 좋음(SSR->0), 일반적으로 0.2는 넘어야 한다고 봄
R-square = SSE/SST = 1 – SSR/SST
SST = sum(y_i – mean(y))^2: 관측값에서 관측값의 평균을 뺀 결과의 총합
SSE = sum(y_i_hat – mean(y))^2: 추정값에서 관측값의 평균을 뺀 결과의 총합
SSR = sum(y_i-y_i_hat)^2: 관측값에서 추정값을 뺀 값(residual)의 총합
- p-value
귀무가설이 맞다는 전제하에 통계값이 실제로 관측된 값 이상일 확률을 의미
일반적으로 p-value는 어떤 가설이 맞다는 가정 하에 내가 구한 통계값이 얼마나 자주 나올까?
신뢰도 95%: p-value < 0.05, 귀무가설을 기각하고 대립가설이 참이 된다.

우리는 미세먼지 관련 feature들을 이용하여 해당 업종의 매출을 예측하는 회귀모형을 만들었고 
R-square(>0.3) 값으로 해당 model의 설명력(성능)을 검증한 후 각 변수에 따라 p-value(<0.05, 통계적 유의성)을 확인하였습니다.


